{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework-  26.11.2018:\n",
    "## State of the Art Neural Network Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The purpose of this homework is to implement and evaluate the sota architectures presented in the lecture.\n",
    "However, you are encouraged to try your own layer module ideas.\n",
    "Feel free to consult the [Keras source code](https://github.com/keras-team/keras-applications):\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Based on the CNN modules presented in the lecture e.g. VGG16, Inception, ResNet, Xception, DenseNet, come up with your own CNN module and write a small text discussing your idea and motivations behind the module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Evaluate all your module using the Keras CIFAR10 dataset splits (The model with best test accuracy will present their solution to the class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Evaluate your module using the FERPlus dataset (The model with the best test accuracy will present their solution to the class).\n",
    "\n",
    "    3.1 Download the [FER2013 dataset](https://www.kaggle.com/c/challenges-in-representation-learning-facial-expression-recognition-challenge/data) (images_path).\n",
    "    \n",
    "    3.2 Download the [FERPlus labels](https://github.com/Microsoft/FERPlus/blob/master/fer2013new.csv) (labels_path).\n",
    "    \n",
    "    3.3 Use the following code snippet to load the dataset giving the appropiate paths to the csv files downloaded in 3.1 and 3.2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FERPlus(object):\n",
    "    \"\"\"Class for loading FER2013 [1] emotion classification dataset with\n",
    "    the FERPlus labels [2]:\n",
    "    [1] kaggle.com/c/challenges-in-representation-learning-facial-\\\n",
    "            expression-recognition-challenge\n",
    "    [2] github.com/Microsoft/FERPlu://github.com/Microsoft/FERPlus\"\"\"\n",
    "\n",
    "    def __init__(self, images_path, labels_path, split='train', image_size=(48, 48),\n",
    "                 dataset_name='FERPlus'):\n",
    "\n",
    "        self.split = split\n",
    "        self.image_size = image_size\n",
    "        self.dataset_name = dataset_name\n",
    "        self.images_path = images_path\n",
    "        self.labels_path = labels_path\n",
    "        self.class_names = ['neutral', 'happiness', 'surprise', 'sadness',\n",
    "                            'anger', 'disgust', 'fear', 'contempt']\n",
    "        self.num_classes = len(self.class_names)\n",
    "        self.arg_to_name = dict(zip(range(self.num_classes), self.class_names))\n",
    "        self.name_to_arg = dict(zip(self.class_names, range(self.num_classes)))\n",
    "        self._split_to_filter = {\n",
    "            'train': 'Training', 'val': 'PublicTest', 'test': 'PrivateTest'}\n",
    "\n",
    "    def load_data(self):\n",
    "        filter_name = self._split_to_filter[self.split]\n",
    "        pixel_sequences = pd.read_csv(self.images_path)\n",
    "        pixel_sequences = pixel_sequences[pixel_sequences.Usage == filter_name]\n",
    "        pixel_sequences = pixel_sequences['pixels'].tolist()\n",
    "        faces = []\n",
    "        for pixel_sequence in pixel_sequences:\n",
    "            face = [float(pixel) for pixel in pixel_sequence.split(' ')]\n",
    "            face = np.asarray(face).reshape(48, 48)\n",
    "            faces.append(cv2.resize(face, self.image_size))\n",
    "        faces = np.asarray(faces)\n",
    "        faces = np.expand_dims(faces, -1)\n",
    "\n",
    "        emotions = pd.read_csv(self.labels_path)\n",
    "        emotions = emotions[emotions.Usage == filter_name]\n",
    "        emotions = emotions.iloc[:, 2:10].values\n",
    "        N = np.sum(emotions, axis=1)\n",
    "        mask = N != 0\n",
    "        N, faces, emotions = N[mask], faces[mask], emotions[mask]\n",
    "        emotions = emotions / np.expand_dims(N, 1)\n",
    "        return faces, emotions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
