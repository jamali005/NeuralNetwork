{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Team Members : \n",
    "\n",
    "### Hammam Abdelwahab\n",
    "### Lemrabet Najlae\n",
    "### Jamali Hatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YLZ0HE7Hf65_"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sympy as sp\n",
    "sp.init_printing(use_latex=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKk9GXGqc4QW"
   },
   "source": [
    "# Models of a neuron\n",
    "## 1.1 \n",
    "\n",
    "Given the logistic function, use sympy for proof as follows: \n",
    "$f(v)= \\frac{1}{1+exp(-av)} $ \n",
    "\n",
    "\n",
    "$ \\frac{\\partial f}{\\partial v} = af(v)[1-f(v)] $  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The derivation is:'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGcAAAAzBAMAAAB4cAsrAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAIpmJdu8QRM1mu90yVKvMIHo8AAAACXBIWXMAAA7EAAAOxAGVKw4bAAACA0lEQVRIDWNgwAvYVF4cYPdjMMarCF0y+8D5BGb+hFvo4nj5SgynGcSqGZjxKoJL8q4CgmUMsQx+DEDHlcPFiWCwfWRYmcawncEBr1ohI9cEBjYTJwGoqhie7xMY9jBewKeJPZChn4GhWoDRAKqqztdpAkOdJz49DKkTGLQYGGMZkg7gVYYqqZ/AsIWBL9JlGqowfl4UA9sfBv4H+BWhybJ9ZuD9wMAP8xCaLA4u218GroaLrEBNDjhUYBNuYZj9wIClgSFJAJssDrE854NPChicPCfgkB8VHgEh8J908IHkYDFalECyHmYBvgaSNXEL8HwkXVMB43eSNTEw8H4jQxO3AxmajMB6GInNp5ygQoBTAaxJCkwSQzwEKipmqAEpbQTiqwkgFnaAqNgyGBh4eu8uAyoD2sf26H0CVMMVTI2Iio3ZgYH1/39QKuIGudQ/AaoYiyZExcYWAFXFIA1iYNWEWbG1wzQ5YdWEqKOQKzZIcAM1rMSqCamOQqrYZsBs2otNE3IdhVSx3YZpCkdosujo2NrR0QcUwFFHnceiCSgEDT0cdRRcE1bn4aijqmE2YQ0IHHUUPCDAwYgeTyzY6yhlmE0gK/Xi+yZA+LAUgb2O6oFpAicjGAcWEHA+CoNxA4wLzSBQbiJMGBsNTLAwsBDGIEgDswYMEJ8JkYwnLbuDrAIAIPazLLkVqdQAAAAASUVORK5CYII=\n",
      "text/latex": [
       "$$\\frac{a e^{- a v}}{\\left(1 + e^{- a v}\\right)^{2}}$$"
      ],
      "text/plain": [
       "     -a⋅v   \n",
       "  a⋅ℯ       \n",
       "────────────\n",
       "           2\n",
       "⎛     -a⋅v⎞ \n",
       "⎝1 + ℯ    ⎠ "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def f(a,v):\n",
    "    \"\"\"\n",
    "    The sigmoid function\n",
    "    \"\"\"\n",
    "    return 1 / (1 + sy.exp(-a*v))\n",
    "\n",
    "v = sp.Symbol('v')\n",
    "a = sp.Symbol('a')\n",
    "\n",
    "derivative = sy.diff(f(a,v),v)\n",
    "display(\"The derivation is:\")\n",
    "display(derivative)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And from the derivation we substitute $\\frac{1}{(1+e^{-av})} = f(v)$. \n",
    "\n",
    "Also we substitute $\\frac{1}{(1+e^{-av})}$ = $1 - \\frac{1}{1+e^{-av}}$\n",
    "\n",
    "Therefore, \n",
    "$$\\frac{\\partial f}{\\partial v} = a f(v)(1 - \\frac{1}{1+e^{-av}}) = af(v)[1-f(v)] $$\n",
    "\n",
    "\n",
    "#### Now to find the derivation in the origin we substitute the 0 as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAsAAAAmBAMAAADgsHz9AAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAIpmJdu8QRM1mu90yVKvMIHo8AAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAiklEQVQYGWNgYFRWCWNgYCgV4PjAwMAWycC0gIGB6RsDtwMDA+sChvwDDAz5Bgz3GYDUBYYVvAIMHA6c+5iBKp/YyLkDRckE/0EAaCFRgEcBrIx7AZhyBVOMM8AUMweYmgim2BzAFDMDmLoDptgMwBTvu3fv4xwYgIB1AZBgYOAHU8zr/00AcxkYAFdvIhyRS2oKAAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$$\\frac{a}{4}$$"
      ],
      "text/plain": [
       "a\n",
       "─\n",
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(derivative.subs(v,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JNQkmBGVirY1"
   },
   "source": [
    "## 1.3 \n",
    "$g(v)= \\frac{v}{\\sqrt{1+v^2}} $  \n",
    "\n",
    "$\\frac{\\partial f}{\\partial v} = f^3(v)/v^3 $  \n",
    "\n",
    "Same here we use sympy to find the derivation as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1570273093863,
     "user": {
      "displayName": "Hatim JAMALI",
      "photoUrl": "",
      "userId": "12031217391056068623"
     },
     "user_tz": -120
    },
    "id": "JdqTvN1UkE4t",
    "outputId": "5650fe8e-ecec-4e2a-f0a0-2b44d0d1dfb5"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAM8AAAA6BAMAAADl8BDGAAAAMFBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAv3aB7AAAAD3RSTlMAEM3dMnaZZolU76siRLtrPhwCAAAACXBIWXMAAA7EAAAOxAGVKw4bAAADY0lEQVRYCe1XPWsUQRh+9/a+9r6yaCOJkGO1kViciAga4bASm1yjbU60kYhco1hYHIF8CBZBEYyF0fsDEREFm5xaiJWHWmghORsbLaJCqsg6s7OzezM3s3NzbkTEgduZeZ55n2f33bndfQGiW/bimegFcbHX4WFcUtE6kzDVjl4RE3sMXndiklLJrNiqFTHxh2LSUclk66oV/fydYZJwuV9HgRiP14YwKjaLVYVwPz09hNHx5bv6UXpGxumacRhWXbf/jFWInlHWugdHVZJiXs/oVboCt8VCKlTPyM7V4INKUszrGcG6DTWxkArVNDoL0FRJinlNoy9gVcVCKlTTaBZ2qRQlvKZRfqEhEVLAM6sTQ0YqhP8Z2hpy82sn4L+RdspowN+auh0HcdsLI+7AbQNdU9Zx9rQc5wEaDhSJY4Zt25q65KVzwXltq1Gpc+PPGBmwKDUqRN3kIGrQwYlusJJPXb7jUXFVVG+kRs8JE09FlYKRNnUyghFBzpMunopqFE5SH743KgTRqKjmP9u8Cp1n5h7RId+nlyiywodLqotsO1+mMRr9zmAtrahuEaS/unhJCLOd3AqCwsFVPMQ7OISY0QKdBRWVbwTAfawUumSp2Sn8pEE9fb7dM+kf0lsEEFRUMqNEoGR944Ss+wBGGYHJxa/oKGqpBpD6I6yoZEbBmYBZI1L0Lzk2g53n0K8EbwUuHxFmoie6V3+EFZXMaDKQmPdH1AhS2GgU/RIwzm8pgFQLMacASP0RVlQSo0LFl4dM3R+xRokOhm/6XE/3bBoxKJqpP2Yd54jjTHjL2M2QqqP74FV57+EdkWGNvN1k7O9xoMPxLmSaaLLO1h+SKyo1/Cwn9y1/IhKsUaaM0DGbUMwxvQUmxrn6Q2JkLvlZzrnuBtFhjawKuuQLog//wiZcwRFc/SExynXYLPd8FZDNkET2pvuDnAN7XLMPYICrPyKMuCyzV4SNJG3qWh0zXP1BjbjqAqeOyzJrVKxgMWFLtGwBTo04Cm8GLsuskbcZuCB/am2K8N0iEO24OsLZLLNG6aY4EKOiTS9b7WWGzTI1Sj/9/gQ9FaqyUE08fATRQGpE5i8o/Lt9+FClSuxXAX6oxtJK7UgZoxxJa5D0xScJUZyHJEoI+69yIQfgvcol3ADwL7xFG6Zmn7MoAAAAAElFTkSuQmCC\n",
      "text/latex": [
       "$$- \\frac{v^{2}}{\\left(v^{2} + 1\\right)^{\\frac{3}{2}}} + \\frac{1}{\\sqrt{v^{2} + 1}}$$"
      ],
      "text/plain": [
       "        2                  \n",
       "       v             1     \n",
       "- ─────────── + ───────────\n",
       "          3/2      ________\n",
       "  ⎛ 2    ⎞        ╱  2     \n",
       "  ⎝v  + 1⎠      ╲╱  v  + 1 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "v = sp.symbols('v') \n",
    "a = sp.symbols('a') \n",
    "f = v/sp.sqrt(1+v**2) #defines f as a symbolic function\n",
    "df=sp.diff(f, v)\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now adding this result together to become: \n",
    "    \n",
    "$\\frac{v^2}{(v^2 + 1)^{\\frac{3}{2}}}$ + $\\frac{1}{\\sqrt{v^2+1}}$ = \n",
    "$\\frac{-v^2 + v^2 +1 }{(\\sqrt{v^2 + 1})^2}$ = \n",
    "$\\frac{\\partial f}{\\partial v} = \\frac{v^3}{(\\sqrt v^2+1 )^3} * \\frac{1}{v^3}= \\frac{\\varphi ^3}{v^3}$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we subtitute for at the origin as follows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAAgAAAAPBAMAAAArJJMAAAAAHlBMVEX///8AAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAACGjDitAAAACXRSTlMAVO8Qq5l2zWYZcMvdAAAACXBIWXMAAA7EAAAOxAGVKw4bAAAAHUlEQVQIHWNgAANGZQYGk5DJQDYbqQSr03QPsBkAJYgIYEZbtZEAAAAASUVORK5CYII=\n",
      "text/latex": [
       "$$1$$"
      ],
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.subs(v,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1i_jQJjzlV7d"
   },
   "source": [
    "# Network architectures\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_hykBlNywo9S"
   },
   "source": [
    "#### 1.12\n",
    "\n",
    "The architectural graph for the neural network is as follows: \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d26BRKmPknu6"
   },
   "source": [
    "![](Neural51.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.13. a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The input-output mapping for the network is depicted as follows: \n",
    "\n",
    "$Y = \\varphi(-2\\varphi(3\\varphi(5X_1+X_2)-\\varphi(2X_1-3X_2))+\\varphi(4\\varphi(5X_1+1X_2)+6\\varphi(2X_1-3X_2)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.13. b \n",
    " supposing that the output neuron operates in the linear region. Then: \n",
    " \n",
    " $\\varphi(x) \\approx \\alpha x$\n",
    " \n",
    " and the output vector $y_k \\approx \\alpha w^{T}_{k}x$\n",
    " \n",
    "  $\\left(\n",
    "    \\begin{array}{c}\n",
    "      y_{1} \\\\\n",
    "      \\vdots  \\\\\n",
    "      y_{m}\n",
    "    \\end{array}\n",
    "  \\right) $ = $\\alpha \\left(\n",
    "    \\begin{array}{c}\n",
    "      w_{1}^T \\\\\n",
    "      \\vdots  \\\\\n",
    "      w_{m}^T\n",
    "    \\end{array}\n",
    "  \\right) x = \\alpha W x$\n",
    "  \n",
    "  and the output becomes: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Y = \\alpha(-2\\alpha(3\\alpha(5X_1+X_2)-\\alpha(2X_1-3X_2))+\\alpha(4\\alpha(5X_1+1X_2)+6\\alpha(2X_1-3X_2)))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# knowledge Representation\n",
    "\n",
    "\n",
    "#### 1.21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to (simard 1992) the transformation s(P,a) can be depicted by the Taylor expansion of the transformation s as follows:$$ s(x,\\alpha) = s(x,0) + \\partial \\frac{s(x,\\alpha)}{\\partial \\alpha} + O(\\alpha ^2) \\approx x + \\alpha T$$This\n",
    "equation shows that the linear approximation is characterized\n",
    "completely by the point p (x) and the tangent vector. If we consider\n",
    "alpha as a rotation angle, ||a|| < 1 shows good linear approximation,\n",
    "and if a = 0 then transformation will result to the same input (image).According\n",
    "to (simard 1992) the reason that for infinitesimal (or an isomorphism)\n",
    "transformation, there exists a direct correspondence between the tangent\n",
    "vectors of the tangent plane and the compositions of transformations.For\n",
    "example, if we take three tangent vectors for rotation, we will\n",
    "generate a tangent plane corresponding to all possible compositions of  rotations.\n",
    "Hencefore, the resulting tangent distance is considered locally\n",
    "invariant to all rotations (of any center). This also applies to\n",
    "X-translations and Y-translations.\n",
    "\n",
    "##### reference: Transformation Invariance for Pattern Recognition-Tangent Distance and Tangent Probagation.\n",
    "http://yann.lecun.com/exdb/publis/pdf/simard-00.pdf"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "NNassignement1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
